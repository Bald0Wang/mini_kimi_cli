## Mini Kimi 新手入门学习指南

欢迎来到 **Mini Kimi** 的学习之旅！这是一个精简版的 AI Agent 实现，旨在帮助你用最少的代码理解 LLM Agent 是如何工作的。

本指南将带你一步步拆解项目，从运行到源码分析，再到动手实战。

> 如果你更喜欢“每章一份独立讲义”的阅读方式，请直接看：`mini_kimi/docs/新手入门/README.md`。

---

## 第一阶段：环境与运行（Getting Started）

**目标**：成功运行项目，体验 Agent 的能力。

1.  **环境准备**
    *   确保安装 Python 3.10+。
    *   安装依赖：`pip install openai ddgs`。
    *   获取 API Key：准备一个 Moonshot AI (Kimi) 的 API Key。

2.  **配置与启动**
    *   设置环境变量 `MOONSHOT_API_KEY`。
    *   推荐从项目根目录运行，并设置 `PYTHONPATH`：

```powershell
$env:PYTHONPATH="mini_kimi/src"
python mini_kimi/src/mini_kimi/ui/shell/main.py
```

    *   也可以进入 `mini_kimi` 目录运行（同样需要 `PYTHONPATH` 指向 `src`）。

3.  **体验功能**
    *   **基础对话**：和它打个招呼。
    *   **联网搜索**：试着问“Python 3.13 有什么新特性？”（观察它是如何调用 `SearchWeb` 和 `FetchURL` 的）。
    *   **系统操作**：试着让它“创建一个名为 hello.txt 的文件，内容是 Hello World”（观察 `WriteFile` 工具的调用）。

---

## 第二阶段：核心概念理解 (Core Concepts)

**目标**：在看代码前，理解 Agent 背后的理论基础。

1.  **什么是 Agent (智能体)？**
    *   理解 **感知 (Perception)** -> **思考 (Brain)** -> **行动 (Action)** 的循环。
    *   Mini Kimi 属于 **CLI Agent**，通过命令行与操作系统交互。

2.  **什么是 ReAct 模式？**
    *   **Reasoning (推理)**：模型先思考“我需要做什么？”。
    *   **Acting (行动)**：模型选择调用某个工具。
    *   **Observation (观察)**：工具执行的结果反馈给模型。
    *   *思考：为什么 LLM 需要看到工具的执行结果才能进行下一步？*

---

## 第三阶段：源码深度剖析 (Code Walkthrough)

**目标**：读懂核心代码，理解各模块职责。建议按照以下顺序阅读：

### 1. LLM 层：与大脑通信
*   **文件**：`src/mini_kimi/llm/client.py`
*   **重点**：
    *   如何初始化 `OpenAI` 客户端。
    *   `tools` 参数是如何传递给 API 的（将 Python 函数定义转为 JSON Schema）。

### 2. Tools 层：Agent 的手脚
*   **文件**：`src/mini_kimi/tools/` 下的各个文件。
*   **重点**：看 `BashTool` 或 `WriteFileTool`。
    *   `schema` 字典：告诉 LLM 这个工具怎么用（函数名、参数描述）。
    *   `__call__` 方法：工具被调用时真正执行的代码。

### 3. Soul 层：核心循环 (最重要！)
*   **文件**：`src/mini_kimi/soul/soul.py`
*   **重点**：
    *   `System Prompt`：我们是如何设定 Kimi 的人设和规则的？
    *   `run` 方法中的 `while` 循环：这就是 ReAct 的具体实现。
        *   **Step 1**: `llm.chat(...)` 获取模型回复。
        *   **Step 2**: 检查 `tool_calls`。如果有，解析函数名和参数。
        *   **Step 3**: 执行对应工具 (`tool_inst(...)`)。
        *   **Step 4**: 将结果封装为 `role: tool` 的消息追加到历史记录中。

### 4. UI 层：交互入口
*   **文件**：`src/mini_kimi/ui/shell/main.py`
*   **重点**：简单的 `input()` 循环和路径配置。

---

## 第四阶段：动手实战 (Hands-on Labs)

**目标**：通过修改代码来验证你的理解。

### Lab 1：修改 System Prompt
*   **任务**：修改 `src/mini_kimi/soul/soul.py` 中 `Soul.__init__` 里写入 `self.messages[0]["content"]` 的系统提示词（目前项目未抽成 `_get_system_prompt`）。
*   **尝试**：把 Kimi 变成一个说话只用“古文”的助手，或者限制它“严禁使用 Bash 工具”。
*   **验证**：运行程序，看它的说话风格是否改变。

### Lab 2：添加一个简单的计算器工具
*   **任务**：在 `src/mini_kimi/tools/` 下创建一个 `calc` 目录和工具。
*   **步骤**：
    1.  定义 `AddTool` 类，包含 `schema`（两个参数 x, y）和 `__call__`（返回 x+y）。
    2.  在 `soul.py` 中注册这个新工具。
*   **验证**：问 Kimi “12345 加 67890 等于多少？”，看它是否调用了你的新工具。

### Lab 3：给 Web 搜索增加“阅读限制”
*   **任务**：修改 `SearchWebTool`。
*   **挑战**：目前的搜索结果可能很长。尝试在代码里截断搜索摘要，只保留前 100 个字符，看看这是否会影响 LLM 的判断？（体验 Context Window 的重要性）。

---

## 第五阶段：进阶思考 (Next Steps)

当你完全掌握了 Mini Kimi，可以思考以下问题，这正是完整版 **Kimi CLI** 解决的问题：

1.  **记忆管理**：如果对话太长，超过了 Token 限制怎么办？（需要上下文压缩）。
2.  **工具安全**：如果 LLM 想要执行 `rm -rf /` 怎么办？（需要权限审核机制）。
3.  **复杂任务**：如果任务太难，一个 Agent 搞不定怎么办？（需要多 Agent 协作）。

祝你学习愉快！

---

## 模块化学习（按 `参考.md` 的写法：目标 → 文件 → 关键点 → 检查点 → 练习）

本部分把 Mini Kimi 拆成 4 个模块，建议按顺序完成。每个模块都能独立验收（有检查点），并且能自然过渡到下一个模块。

### 模块 0：先建立“全局地图”（你到底在学什么）

**学习目标**

- 说清楚 Mini Kimi 在做什么：**LLM + 工具 + 循环**
- 知道代码分层在哪里：`ui/`、`soul/`、`llm/`、`tools/`

**必读文件**

- `mini_kimi/docs/结构说明.md`
- `mini_kimi/src/mini_kimi/ui/shell/main.py`

**检查点（完成标准）**

- 你能用一句话解释：`main.py` 负责**读入用户输入**并把输入交给 `Soul.run()`。

---

### 模块 1：LLM 层（模型是怎么被调用的）

**学习目标**

- 理解一次对话请求的最小数据：`messages`（system/user/tool/assistant）
- 理解工具调用是怎么交给 OpenAI 兼容接口的：`tools=[{type:function, function:{...}}]`
- 理解 API Key 加载优先级

**必读文件**

- `mini_kimi/src/mini_kimi/llm/client.py`

**关键点（结合项目代码）**

- `LLMClient.chat(messages, tools)`：把工具的 `schema` 传给接口，让模型能够返回 `tool_calls`。
- `get_api_key()`：优先使用 `MOONSHOT_API_KEY`，其次尝试读取用户目录下的配置文件（如果存在）。

**检查点**

- 能解释：为什么把工具 `schema` 传给模型后，模型就能“结构化地”返回工具调用？

**练习（可选）**

- 把 `temperature` 从 `0.3` 改成 `0.7`，对比输出差异（更发散 vs 更稳定）。

---

### 模块 2：Soul 层（ReAct 循环到底长什么样）

**学习目标**

- 理解循环的 3 个关键状态：`messages`、`tool_calls`、`tool_result`
- 能完整描述 ReAct：模型输出工具调用 → 执行工具 → 把结果塞回对话 → 再问模型
- 理解“最大步数”是为了防止无限循环

**必读文件**

- `mini_kimi/src/mini_kimi/soul/soul.py`

**关键点（按运行顺序）**

- `self.messages`：对话历史，`self.messages[0]` 是 system prompt。
- `self.tools` / `self.tool_map`：工具注册与分发。
- 主循环：
  - 调 `self.llm.chat(self.messages, self.tools)`
  - 如果有 `tool_calls`：解析 JSON 参数并执行工具
  - 把工具输出以 `role: tool` 写回 `self.messages`
  - 直到模型给出最终 `content`

**检查点**

- 你能指出：工具结果是以哪种 `role` 追加回历史里的？（提示：`role: tool`）

**练习（强烈推荐）**

- 在 `Soul.run()` 中增加一行调试打印：打印当前 `len(self.messages)`，观察一次任务会增长多少条消息。

---

### 模块 3：Tools 层（工具如何“被模型看懂”并且安全执行）

**学习目标**

- 理解工具的两部分：`schema`（让模型会用） + `__call__`（真正执行）
- 明白“工具输出要可控”：要截断、要避免爆长内容
- 理解 web 工具的“深度限制”是靠 prompt 约束（目前未做硬限制）

**必读文件**

- `mini_kimi/src/mini_kimi/tools/bash/bash_tool.py`
- `mini_kimi/src/mini_kimi/tools/file/write_tool.py`
- `mini_kimi/src/mini_kimi/tools/web/search_tool.py`

**关键点**

- `BashTool`：`subprocess.run(..., shell=True)`，要注意平台差异（Windows vs Linux）。
- `WriteFileTool`：会覆盖写入；当前仅做了简单的 `..` 拦截。
- `SearchWebTool`：依赖 `ddgs`（所以需要 `pip install ddgs`）。
- `FetchURLTool`：抓取网页并做粗略文本化，输出会截断。

**检查点**

- 你能解释：为什么 `SearchWebTool.schema["function"]["name"]` 必须和 `Soul` 里路由的工具名一致？

---

## 常见问题与排错（新手最容易卡住的点）

### 1) `ModuleNotFoundError: No module named 'mini_kimi'`

- **原因**：运行方式导致 Python 找不到包根目录。
- **解决**：从项目根目录运行，并设置 `PYTHONPATH` 指向 `mini_kimi/src`（见第一阶段的命令）。

### 2) 搜索工具报缺少依赖

- **现象**：`ImportError` 或提示安装 ddgs。
- **解决**：执行 `pip install ddgs`。

### 3) Moonshot 401 / Invalid Authentication

- **原因**：`MOONSHOT_API_KEY` 未设置或无效。
- **解决**：设置环境变量后重启终端，再运行。

---

## 扩展路线（学完 Mini Kimi 后，如何过渡到完整版）

如果你要进一步理解完整的 `kimi-cli`，建议按能力补齐：

- **上下文工程**：长对话压缩、摘要、裁剪策略
- **工具安全**：审批/白名单/沙箱
- **多智能体**：subagent 的任务分解与事件转发


